# âœ… Sistema Ottimizzato - Modifiche Applicate

## ğŸ¯ Cosa Abbiamo Sistemato

### 1ï¸âƒ£ UI - Solo Ultima Descrizione
**Prima**: Accumulava tutte le descrizioni (scroll infinito)
```
[5s | Frame 75] Person enters room
[10s | Frame 150] Person sits down
[15s | Frame 225] Person stands up
...
```

**Ora**: Mostra SOLO l'ultima descrizione (sempre aggiornata)
```
[Frame 150] Person sitting at desk
```

âœ… **Benefit**: Chiaro, pulito, sempre la info piÃ¹ recente visibile

---

### 2ï¸âƒ£ Descrizioni PiÃ¹ Brevi
**Prima**: 
- max_new_tokens=50
- Prompt: "Describe what's happening in this scene. Who is present? What are they doing?"
- Risultato: ~40-50 parole

**Ora**:
- max_new_tokens=25
- Prompt: "What's happening? Be brief."
- Trim alla prima frase se troppo lungo
- Risultato: ~10-20 parole

**Esempio**:
- Prima: "In this image, we can see a person who is sitting at a desk. They appear to be working on a computer. The room has white walls and..."
- Ora: "Person sitting at desk working on computer."

âœ… **Benefit**: 2Ã— piÃ¹ veloce, piÃ¹ leggibile, real-time

---

### 3ï¸âƒ£ Video di Test Creato
Creato `test_visual.mp4`:
- 15 secondi, 15 FPS
- 5 scene con testo grande
- Cambi di scena chiari ogni 3 secondi:
  1. "PERSON ENTERS ROOM" (blu)
  2. "PERSON SITS DOWN" (verde)
  3. "PERSON STANDS UP" (rosso)
  4. "PERSON WAVES HAND" (arancione)
  5. "PERSON LEAVES ROOM" (viola)

âœ… **Benefit**: Test perfetto per vedere quanto velocemente SmolVLM rileva cambiamenti

---

## ğŸ¬ Come Testare Ora

### Test 1: Video Sintetico (Scene Chiare)
```powershell
cd e:\dev\ai-director\smolvlm-audio-transcription
& .\.venv\Scripts\python.exe main_video.py test_visual.mp4 --frames 10 --no-audio
```

**Cosa Osservare**:
- Ogni 10 frame (ogni ~0.67 sec) una nuova descrizione
- SmolVLM deve rilevare il testo sullo schermo
- Descrizioni brevi tipo: "Text says person enters room"
- UI mostra SOLO ultima descrizione

---

### Test 2: Video Reale con Persone
```powershell
# Se hai sample_speech.mp4 o altro video reale
& .\.venv\Scripts\python.exe main_video.py sample_speech.mp4 --frames 15 --no-audio
```

**Cosa Osservare**:
- Descrizioni tipo: "Person speaking at podium" 
- Cambio quando persona si muove
- Max 1-2 righe di testo

---

## ğŸ¨ UI Aggiornata

### Browser: index_video.html

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ¬ AI DIRECTOR SYSTEM                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     â”‚                          â”‚
â”‚  ğŸ“¹ Video Stream    â”‚ ğŸ” Vision Analysis       â”‚
â”‚  [Frame real-time]  â”‚ [Frame 120] Person talks â”‚
â”‚                     â”‚                          â”‚
â”‚                     â”‚ (Solo ultima, no scroll) â”‚
â”‚                     â”‚                          â”‚
â”‚                     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     â”‚ ğŸ¤ Audio Transcription   â”‚
â”‚                     â”‚ (Non attivo --no-audio)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Statistiche
- **Frame Count**: Frame ricevuti dal browser
- **Word Count**: Parole nell'ultima descrizione (non piÃ¹ transcription)
- **FPS Received**: Frame al secondo nel browser

---

## ğŸ“Š Performance Attese

### Video 15 FPS, --frames 10

```
Video Stream:     15 FPS (fluido)
Analisi SmolVLM:  1.5 analisi/sec (ogni 10 frame)
Latency:          ~50-80ms per analisi
GPU Usage:        ~40-50%
Descrizione:      10-20 parole (1-2 righe)
```

### Video 15 FPS, --frames 5 (piÃ¹ veloce)

```
Video Stream:     15 FPS (fluido)
Analisi SmolVLM:  3 analisi/sec (ogni 5 frame)
Latency:          ~50-80ms per analisi
GPU Usage:        ~70-90%
Descrizione:      10-20 parole (1-2 righe)
```

---

## ğŸ¯ Per Video con Audio Reale

### Problema Attuale
`sample_speech.mp4` non ha dialoghi parlati (solo musica/ambient sound)

### Soluzione 1: Scarica Video con Dialogo da YouTube
```powershell
# Installa yt-dlp se non ce l'hai
pip install yt-dlp

# Scarica TED Talk (1 minuto)
yt-dlp -f "best[height<=480]" `
    --output "ted_sample.mp4" `
    --download-sections "*0:00-1:00" `
    "https://www.youtube.com/watch?v=8jPQjjsBbIc"

# Testa con audio
& .\.venv\Scripts\python.exe main_video.py ted_sample.mp4 --frames 15
```

### Soluzione 2: Usa Video Esistenti
Se hai video personali con persone che parlano:
```powershell
& .\.venv\Scripts\python.exe main_video.py "C:\path\to\your\video.mp4" --frames 15
```

**Note**: L'audio transcription (Moshi) Ã¨ disabilitato con `--no-audio` per evitare errori Triton. Per riabilitarlo serve installare Triton (complicato su Windows).

---

## ğŸš€ Prossimi Step per AI Director

Ora che il sistema base funziona con:
- âœ… Video fluido a FPS nativi
- âœ… Analisi real-time asincrona
- âœ… Descrizioni brevi e aggiornate
- âœ… UI pulita e leggibile

**Siamo pronti per**:

### 1. Multi-Stream Manager
Gestire 4-6 video contemporaneamente:
```python
stream1 = VideoProcessor("cam1.mp4", analyzer, analyze_every_n_frames=30)
stream2 = VideoProcessor("cam2.mp4", analyzer, analyze_every_n_frames=30)
stream3 = VideoProcessor("cam3.mp4", analyzer, analyze_every_n_frames=30)
stream4 = VideoProcessor("cam4.mp4", analyzer, analyze_every_n_frames=30)
```

### 2. Priority Scoring
Calcolare quale stream Ã¨ piÃ¹ interessante:
```python
def calculate_priority(description: str) -> float:
    score = 0.0
    
    # Keywords detection
    if "person" in description.lower():
        score += 3.0
    if any(word in description.lower() for word in ["talking", "speaking", "gesturing"]):
        score += 4.0
    if any(word in description.lower() for word in ["walking", "moving", "running"]):
        score += 2.0
    
    return score
```

### 3. Auto-Switching Logic
```python
# Pseudo-code
while True:
    scores = {
        "cam1": calculate_priority(cam1_description),
        "cam2": calculate_priority(cam2_description),
        "cam3": calculate_priority(cam3_description),
        "cam4": calculate_priority(cam4_description),
    }
    
    best_camera = max(scores, key=scores.get)
    if best_camera != current_camera:
        switch_to(best_camera)
```

### 4. n8n Integration
Workflow n8n che:
- Riceve eventi da API server
- Decide switch logica
- Invia comandi al sistema
- Registra/notifica eventi importanti

---

## ğŸ“ Comandi Rapidi

### Avvia Sistema
```powershell
cd e:\dev\ai-director\smolvlm-audio-transcription
& .\.venv\Scripts\python.exe main_video.py test_visual.mp4 --frames 10 --no-audio
```

### Crea Nuovo Video di Test
```powershell
& .\.venv\Scripts\python.exe create_test_video.py
```

### Scarica Video con Dialogo
```powershell
# Usa lo script incluso
.\download_test_videos.ps1
```

### Cambia Frequenza Analisi
```powershell
# PiÃ¹ veloce (ogni 5 frame)
python main_video.py video.mp4 --frames 5 --no-audio

# PiÃ¹ lento (ogni 30 frame)
python main_video.py video.mp4 --frames 30 --no-audio
```

### Monitor GPU
```powershell
# Terminale separato
nvidia-smi -l 1
```

---

## âœ… Checklist FunzionalitÃ 

- [x] Video stream real-time a FPS nativi
- [x] Analisi SmolVLM asincrona
- [x] Descrizioni brevi (10-20 parole)
- [x] UI mostra solo ultima descrizione
- [x] Output minimale (no spam)
- [x] CUDA ottimizzato (FP16, AMP)
- [x] Parametro --frames configurabile
- [x] Video di test sintetico creato
- [ ] Audio transcription (Triton issue)
- [ ] Multi-stream manager
- [ ] Priority scoring
- [ ] Auto-switching
- [ ] n8n integration

---

## ğŸ‰ Sistema Pronto!

Il sistema Ã¨ ora **ottimizzato per real-time** e pronto per evolvere verso l'AI Director multi-camera!

Apri `index_video.html` e osserva:
- Video fluido
- Descrizioni brevi che si aggiornano ogni ~1 secondo
- UI pulita con solo info essenziale

**Prossimo step**: Vuoi che implementiamo il multi-stream manager? ğŸš€
