
## ü§ù Credits
# SmolVLM + Audio + PDF Presentation Control System

This project is an **intelligent multimodal presentation control system** that combines **real-time vision analysis**, **live audio transcription**, and **voice-controlled PDF presentations** using an agent-based architecture. It demonstrates how to build a practical AI system that can:
## üìÑ License
- **Listen** to voice commands via real-time speech-to-text
- **See** and analyze visual content through a vision language model

## üêõ Known Issues
- **Orchestrate** multiple AI agents to work together seamlessly
- VLM server requires ~2GB RAM when loaded
- First-time model downloads can take 5-10 minutes
- Browser may require HTTPS for microphone in production
- Camera controller is currently a stub implementation

## üí° Tips

- Use a good quality microphone for better recognition
- Speak clearly and at moderate pace
- Keep PDF file size reasonable (<50MB) for best performance
- Place the PDF file in the project root directory
- Check all terminal windows for error messages
- Use `./start_all.sh` for hassle-free startup

---

**Happy presenting! üéâ Say "next slide" and watch the magic happen!**

## üéØ What This Project Does

### üé§ Real-time Audio Transcription (STT Agent)
- Continuously listens to your microphone using **Moshi STT** model
- Transcribes speech to text in real-time with low latency
- Sends transcriptions to the Orchestrator for command recognition
- Supports natural language commands like "next slide", "previous slide", "open presentation"

### üé• Real-time Vision Analysis (VLM Agent - Optional)
- Captures video from your webcam at configurable intervals (100ms to 2s)
- Analyzes frames using **SmolVLM-500M** for visual understanding
- Can detect objects and trigger camera control actions
- Ask questions like "What do you see?", "Count the objects", etc.

### üìä PDF Presentation Control System
- **PDF Server**: Serves PDF slides as high-quality images via WebSocket
- **Real-time slide navigation**: Next, previous, go to specific slide
- **Voice control**: Say "next slide" or "previous slide" to navigate
- **Browser-based viewer**: Clean, responsive interface for viewing presentations
- **Multi-client support**: Multiple viewers can connect simultaneously

### üé¨ Camera Controller (Executive Agent - Stub)
- Placeholder for future camera control functionality
- Designed to zoom on detected objects
- Pan, tilt, and zoom operations planned
- Ready for integration with PTZ cameras or software control

### üß† Orchestrator Agent (Central Intelligence)
- **Rule-based decision engine**: Matches voice/vision input to actions
- **Agent coordination**: Routes commands to appropriate executive agents
- **Real-time processing**: Sub-second latency from input to action
- **Extensible rules**: Easy to add new commands and behaviors

## üèóÔ∏è Agent-Based Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Web Browser (GUI)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Unified         ‚îÇ  ‚îÇ  PDF Viewer                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Interface       ‚îÇ  ‚îÇ  - Slide Display            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Video Feed    ‚îÇ  ‚îÇ  - Navigation Controls      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Transcription ‚îÇ  ‚îÇ  - Real-time Updates        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                          ‚îÇ
        ‚îÇ WebSocket                ‚îÇ WebSocket
        ‚îÇ                          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Audio STT       ‚îÇ      ‚îÇ  PDF Server      ‚îÇ
‚îÇ  (Perception)    ‚îÇ      ‚îÇ  (Executive)     ‚îÇ
‚îÇ  Port: 8765      ‚îÇ      ‚îÇ  Port: 9002      ‚îÇ
‚îÇ  - Moshi Model   ‚îÇ      ‚îÇ  - PyMuPDF       ‚îÇ
‚îÇ  - Real-time STT ‚îÇ      ‚îÇ  - Slide Render  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                           ‚îÇ
         ‚îÇ JSON Messages             ‚îÇ Commands
         ‚îÇ                           ‚îÇ
         ‚îÇ        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  Orchestrator Agent       ‚îÇ
                  ‚îÇ  (Central Intelligence)   ‚îÇ
                  ‚îÇ  Port: 9001               ‚îÇ
                  ‚îÇ  - Rule Engine            ‚îÇ
                  ‚îÇ  - Intent Recognition     ‚îÇ
                  ‚îÇ  - Command Delegation     ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚îÇ Commands
                              ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  VLM Server      ‚îÇ              ‚îÇ  Camera Controller   ‚îÇ
‚îÇ  (Perception)    ‚îÇ              ‚îÇ  (Executive - Stub)  ‚îÇ
‚îÇ  Port: 8080      ‚îÇ              ‚îÇ  - Zoom Controls     ‚îÇ
‚îÇ  - SmolVLM       ‚îÇ              ‚îÇ  - Pan/Tilt          ‚îÇ
‚îÇ  - Vision        ‚îÇ              ‚îÇ  - Object Tracking   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Agent Roles

**Perception Agents** (Gather data from environment):
- **Audio STT Agent**: Converts speech to text
- **Vision VLM Agent**: Analyzes visual scenes

**Orchestrator Agent** (Makes decisions):
- Receives data from perception agents
- Applies rule-based logic to recognize intent
- Delegates commands to executive agents

**Executive Agents** (Take actions):
- **PDF Server**: Controls presentation slides
- **Camera Controller**: Controls camera movements (stub)
- **Slide Controller**: Alternative slide control (stub)

## üöÄ Quick Start

### Prerequisites

- macOS (tested on Apple Silicon and Intel)
- Python 3.12+
- Homebrew (for installing llama.cpp)
- Microphone (required)
- Webcam (optional, for VLM features)

### Installation

```bash
# Install system dependencies
brew install llama.cpp portaudio

# Set up Python environment
cd /path/to/smolvlm+audio
python3 -m venv .venv
source .venv/bin/activate

# Install Python packages
pip install --upgrade pip
pip install "numpy<2.0"  # NumPy 1.x for PyTorch compatibility
pip install torch sentencepiece websockets pyaudio moshi PyMuPDF Pillow
```

### Running the Complete System

**Option 1: Automated Startup (Recommended)**
```bash
chmod +x start_all.sh
./start_all.sh
```

This script will:
1. Open 4 separate terminals for each server
2. Start all services automatically
3. Launch the unified web interface
4. Wait 10 seconds for initialization

**Option 2: Manual Startup**

Open 4 separate terminal windows:

**Terminal 1 - VLM Server (Optional)**:
```bash
llama-server -hf ggml-org/SmolVLM-500M-Instruct-GGUF -ngl 99
```

**Terminal 2 - PDF Server**:
```bash
cd /path/to/smolvlm+audio
source .venv/bin/activate
python pdf_server.py
```

**Terminal 3 - Orchestrator**:
```bash
cd /path/to/smolvlm+audio
source .venv/bin/activate
python orchestrator.py
```

**Terminal 4 - Audio STT Server**:
```bash
cd /path/to/smolvlm+audio
source .venv/bin/activate
python main.py
```

**Then open the GUI**:
```bash
open unified_interface.html
```

### Using the System

1. **Grant Permissions**: Allow microphone (and optionally camera) access in browser
2. **Click "‚ñ∂ Start System"**: Activates audio transcription and PDF viewer
3. **Say Commands**:
   - "next slide" - Advance to next slide
   - "previous slide" - Go back one slide
   - "open presentation" - Reset to first slide
4. **View Results**: See live transcription and PDF slides update in real-time

## üìã Voice Commands

The system recognizes the following natural language commands:

### Slide Control Commands
| Voice Command | Action | Description |
|--------------|--------|-------------|
| "next slide" | NEXT_SLIDE | Advance to next slide |
| "previous slide" | PREVIOUS_SLIDE | Go back one slide |
| "open presentation" | OPEN_PRESENTATION | Reset to first slide |

### Vision-Triggered Commands (VLM)
| Detected Object | Action | Description |
|-----------------|--------|-------------|
| "cardboard" | ZOOM_ON_OBJECT | Zoom camera on cardboard (stub) |
| "person" | ZOOM_ON_OBJECT | Zoom camera on person (stub) |
| "bottle" | ZOOM_ON_OBJECT | Zoom camera on bottle (stub) |

*Add custom commands by editing the `_initialize_rules()` method in `orchestrator.py`*

## üîß Configuration

### PDF Server (`pdf_server.py`)
- **Port**: 9002
- **PDF File**: `try.pdf` (place your PDF in project root)
- **Endpoints**:
  - `/viewer` - For web clients viewing slides
  - `/control` - For orchestrator to send commands
- **Render Quality**: 2x zoom for high-quality slides

### Audio STT Server (`main.py`)
- **Port**: 8765
- **Model**: Moshi STT 1B (English/French)
- **Device**: Auto-detects MPS (Apple Silicon) or CPU
- **Sample Rate**: 24kHz
- **Chunk Duration**: ~80ms for low latency

### Orchestrator (`orchestrator.py`)
- **Port**: 9001
- **Rule Engine**: Keyword-based matching
- **Extensibility**: Add rules in `_initialize_rules()`
- **Logging**: Detailed command flow tracking

### VLM Server (Optional)
- **Port**: 8080
- **Model**: SmolVLM-500M-Instruct
- **GPU Acceleration**: Enabled with `-ngl 99`

## üìÅ Project Structure

```
smolvlm+audio/
‚îú‚îÄ‚îÄ main.py                    # Audio STT WebSocket server
‚îú‚îÄ‚îÄ pdf_server.py              # PDF presentation server
‚îú‚îÄ‚îÄ orchestrator.py            # Central orchestrator agent
‚îú‚îÄ‚îÄ CameraController.py        # Camera control stub
‚îú‚îÄ‚îÄ SlideController.py         # Slide control stub (alternative)
‚îú‚îÄ‚îÄ unified_interface.html     # Main web interface
‚îú‚îÄ‚îÄ pdf_viewer.html           # Standalone PDF viewer
‚îú‚îÄ‚îÄ index.html                # Legacy VLM+Audio interface
‚îú‚îÄ‚îÄ start_all.sh              # Automated startup script
‚îú‚îÄ‚îÄ try.pdf                   # Your presentation PDF
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ STARTUP_GUIDE.md          # Detailed startup instructions
‚îú‚îÄ‚îÄ ORCHESTRATOR_GUIDE.md     # Orchestrator documentation
‚îî‚îÄ‚îÄ PDF_SYSTEM_README.md      # PDF system documentation
```

## üé® Web Interfaces

### Unified Interface (`unified_interface.html`)
- **Split-screen layout**: PDF viewer on left, transcription on right
- **Real-time updates**: Slides change as you speak commands
- **Connection status**: Visual indicators for all services
- **Responsive design**: Works on various screen sizes

### PDF Viewer (`pdf_viewer.html`)
- **Standalone viewer**: View PDF without other features
- **Manual controls**: Button-based navigation
- **High-quality rendering**: Crisp, clear slides
- **Slide counter**: Shows current slide and total

## üß™ Testing the System

### Basic Test Flow

1. **Start all servers** (wait for "Ready" messages)
2. **Open unified interface** in browser
3. **Click "Start System"**
4. **Say "next slide"** - Should advance to slide 2
5. **Say "previous slide"** - Should return to slide 1
6. **Check terminal outputs** - See orchestrator logs

### Verifying Components

**Audio STT Working**:
- Speak into microphone
- See transcription appear in real-time
- Check terminal: "Listening for audio to transcribe..."

**Orchestrator Working**:
- Say "next slide"
- Terminal shows: "ORCHESTRATOR: Intent recognized from 'audio_stt'"
- Terminal shows: "Delegating command: NEXT_SLIDE"

**PDF Server Working**:
- Slide image updates in browser
- Terminal shows: "PDF Controller: Next slide -> X/Y"
- Multiple clients can view simultaneously

## üõ†Ô∏è Troubleshooting

### Port Already in Use
```bash
# Kill processes on specific ports
lsof -ti:8765 | xargs kill -9  # Audio STT
lsof -ti:9001 | xargs kill -9  # Orchestrator
lsof -ti:9002 | xargs kill -9  # PDF Server
lsof -ti:8080 | xargs kill -9  # VLM Server
```

### PDF Not Loading
- Ensure `try.pdf` exists in project root
- Check PDF server terminal for errors
- Verify PyMuPDF installed: `pip install PyMuPDF`

### Voice Commands Not Working
- Verify audio server is connected to orchestrator
- Check orchestrator terminal for received messages
- Speak clearly and include exact trigger phrases
- Ensure microphone permissions granted

### Slides Not Updating
- Check PDF server connection in orchestrator terminal
- Verify browser WebSocket connection (unified_interface.html)
- Look for errors in browser console (F12)

### NumPy/PyTorch Errors
```bash
pip uninstall numpy
pip install "numpy<2.0"
pip install torch
```

## üîÆ Future Enhancements

### Planned Features
- [ ] **SmolVLM Integration**: Vision-based slide navigation
- [ ] **Real Camera Control**: PTZ camera integration
- [ ] **Natural Language Understanding**: More flexible command parsing
- [ ] **Slide Content Analysis**: VLM reads and answers questions about slides
- [ ] **Multi-presentation Support**: Switch between different PDFs
- [ ] **Presentation Notes**: Display speaker notes synchronized with slides
- [ ] **Recording**: Save presentation with voice and slide timing
- [ ] **Remote Control**: Mobile app interface

### Extending the System

**Add New Voice Commands**:
Edit `orchestrator.py`:
```python
def _initialize_rules(self):
    return {
        'audio_stt': [
            {
                'trigger': 'your custom phrase',
                'action': 'YOUR_ACTION',
                'params': {'key': 'value'}
            },
        ]
    }
```

**Implement Camera Control**:
Edit `CameraController.py` to integrate with actual camera hardware or software APIs.

**Change PDF File**:
Modify `pdf_server.py`:
```python
pdf_path = Path("your_presentation.pdf")
```

## üéì Use Cases

- üé§ **Voice-Controlled Presentations**: Hands-free slide navigation during talks
- ‚ôø **Accessibility**: Assistive technology for users with mobility limitations
- üìπ **Remote Presentations**: Control slides via voice in video conferences
- ü§ñ **AI Research**: Study multimodal agent architectures
- üéì **Education**: Interactive teaching with voice-controlled content
- üî¨ **Demo Systems**: Showcase AI capabilities to stakeholders
- üíº **Corporate Training**: Hands-free training presentations

## üìö Technical Details

### Models
- **Audio STT**: Moshi STT 1B (~1-2GB download)
- **Vision VLM**: SmolVLM-500M-Instruct GGUF (~500MB download)
- **PDF Rendering**: PyMuPDF (MuPDF engine)

### Frameworks & Libraries
- **Backend**: Python 3.12, asyncio, WebSockets
- **AI Models**: PyTorch, llama.cpp, Moshi
- **PDF Processing**: PyMuPDF (fitz), Pillow
- **Audio**: PyAudio, PortAudio
- **Frontend**: Vanilla JavaScript, WebSocket API

### Communication Protocol
- **Format**: JSON over WebSocket
- **Message Structure**:
  ```json
  {
    "source": "audio_stt",
    "content": "transcribed text"
  }
  ```
- **Command Structure**:
  ```json
  {
    "action": "NEXT_SLIDE",
    "params": {}
  }
  ```

### Performance
- **Audio Latency**: ~80-100ms (STT processing)
- **Command Recognition**: <50ms (Orchestrator)
- **Slide Update**: ~100-200ms (Render + Network)
- **End-to-End**: ~250-400ms (Speech ‚Üí Slide change)

- [SmolVLM](https://huggingface.co/HuggingFaceTB/SmolVLM-500M-Instruct) by HuggingFace
- [kyutaiSTT](https://huggingface.co/kyutai) by Kyutai
- [llama.cpp](https://github.com/ggml-org/llama.cpp) by ggml.org

## License

See [LICENSE](LICENSE) file for details.
# smolvlm-audio-transcription
