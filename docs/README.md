## ğŸ¤ Credits
# SmolVLM + Audio + PDF Presentation Control System

This project is an **intelligent multimodal presentation control system** that combines **real-time vision analysis**, **live audio transcription**, and **voice-controlled PDF presentations** using an agent-based architecture. It demonstrates how to build a practical AI system that can:
## ğŸ“„ License
- **Listen** to voice commands via real-time speech-to-text
- **See** and analyze visual content through a vision language model

## ğŸ› Known Issues
- **Orchestrate** multiple AI agents to work together seamlessly
- VLM server requires ~2GB RAM when loaded
- First-time model downloads can take 5-10 minutes
- Browser may require HTTPS for microphone in production
- Camera controller is currently a stub implementation


---

**Happy presenting! ğŸ‰ Say "next slide" and watch the magic happen!**

## ğŸ¯ What This Project Does

### ğŸ¤ Real-time Audio Transcription (STT Agent)
- Continuously listens to your microphone using **Vosk STT** model
- Transcribes speech to text in real-time with low latency
- Sends transcriptions to the Orchestrator for command recognition
- Supports natural language commands like "next slide", "previous slide", "open presentation"

### ğŸ¥ Real-time Vision Analysis (VLM Agent - Optional)
- Captures video from your webcam at configurable intervals (100ms to 2s)
- Analyzes frames using **SmolVLM-500M** for visual understanding
- Can detect objects and trigger camera control actions
- Ask questions like "What do you see?", "Count the objects", etc.

### ğŸ“Š PDF Presentation Control System
- **PDF Server**: Serves PDF slides as high-quality images via WebSocket
- **Real-time slide navigation**: Next, previous, go to specific slide
- **Voice control**: Say "next slide" or "previous slide" to navigate
- **Browser-based viewer**: Clean, responsive interface for viewing presentations
- **Multi-client support**: Multiple viewers can connect simultaneously

### ğŸ¬ Camera Controller (Executive Agent - Stub)
- Placeholder for future camera control functionality
- Designed to zoom on detected objects
- Pan, tilt, and zoom operations planned
- Ready for integration with PTZ cameras or software control

### ğŸ§  Orchestrator Agent (Central Intelligence)
- **Rule-based decision engine**: Matches voice/vision input to actions
- **Agent coordination**: Routes commands to appropriate executive agents
- **Real-time processing**: Sub-second latency from input to action
- **Extensible rules**: Easy to add new commands and behaviors

## ğŸ—ï¸ Agent-Based Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Web Browser (GUI)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Unified         â”‚  â”‚  PDF Viewer                 â”‚ â”‚
â”‚  â”‚  Interface       â”‚  â”‚  - Slide Display            â”‚ â”‚
â”‚  â”‚  - Video Feed    â”‚  â”‚  - Navigation Controls      â”‚ â”‚
â”‚  â”‚  - Transcription â”‚  â”‚  - Real-time Updates        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                          â”‚
        â”‚ WebSocket                â”‚ WebSocket
        â”‚                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio STT       â”‚      â”‚  PDF Server      â”‚
â”‚  (Perception)    â”‚      â”‚  (Executive)     â”‚
â”‚  Port: 8765      â”‚      â”‚  Port: 9002      â”‚
â”‚  - Vosk Model    â”‚      â”‚  - PyMuPDF       â”‚
â”‚  - Real-time STT â”‚      â”‚  - Slide Render  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â”‚ JSON Messages             â”‚ Commands
         â”‚                           â”‚
         â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â””â”€â”€â”€â”€â”€â”€â”€â”€â–º  Orchestrator Agent       â”‚
                  â”‚  (Central Intelligence)   â”‚
                  â”‚  Port: 9001               â”‚
                  â”‚  - Rule Engine            â”‚
                  â”‚  - Intent Recognition     â”‚
                  â”‚  - Command Delegation     â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ Commands
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  VLM Server      â”‚              â”‚  Camera Controller   â”‚
â”‚  (Perception)    â”‚              â”‚  (Executive - Stub)  â”‚
â”‚  Port: 8080      â”‚              â”‚  - Zoom Controls     â”‚
â”‚  - SmolVLM       â”‚              â”‚  - Pan/Tilt          â”‚
â”‚  - Vision        â”‚              â”‚  - Object Tracking   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Roles

**Perception Agents** (Gather data from environment):
- **Audio STT Agent**: Converts speech to text
- **Vision VLM Agent**: Analyzes visual scenes

**Orchestrator Agent** (Makes decisions):
- Receives data from perception agents
- Applies rule-based logic to recognize intent
- Delegates commands to executive agents

**Executive Agents** (Take actions):
- **PDF Server**: Controls presentation slides
- **Camera Controller**: Controls camera movements (stub)
- **Slide Controller**: Alternative slide control (stub)

## ğŸš€ Quick Start

### Prerequisites

- macOS (tested on Apple Silicon and Intel)
- Python 3.12+
- Homebrew (for installing llama.cpp)
- Microphone (required)
- Webcam (optional, for VLM features)

### Installation

```bash
# Install system dependencies
brew install llama.cpp portaudio

# Set up Python environment
cd /path/to/smolvlm+audio
python3 -m venv .venv
source .venv/bin/activate

# Install Python packages
pip install --upgrade pip
pip install "numpy<2.0"  # NumPy 1.x for PyTorch compatibility
pip install torch sentencepiece websockets pyaudio moshi PyMuPDF Pillow
```

### Running the Complete System

**Automated Startup**
```bash
chmod +x start_all.sh
./start_all.sh
```

This script will:
1. Open 4 separate terminals for each server
2. Start all services automatically
3. Launch the unified web interface
4. Wait 10 seconds for initialization


**Then open the GUI**:
```bash
open unified_interface.html
```

### Using the System

1. **Grant Permissions**: Allow microphone (and optionally camera) access in browser
2. **Click "â–¶ Start System"**: Activates audio transcription and PDF viewer
3. **Say Commands**:
   - "next slide" - Advance to next slide
   - "previous slide" - Go back one slide
   - "open presentation" - Reset to first slide
4. **View Results**: See live transcription and PDF slides update in real-time

## ğŸ“‹ Voice Commands

The system recognizes the following natural language commands:

### Slide Control Commands
| Voice Command | Action | Description |
|--------------|--------|-------------|
| "next slide" | NEXT_SLIDE | Advance to next slide |
| "previous slide" | PREVIOUS_SLIDE | Go back one slide |
| "open presentation" | OPEN_PRESENTATION | Reset to first slide |

### Vision-Triggered Commands (VLM)
| Detected Object | Action | Description |
|-----------------|--------|-------------|
| "cardboard" | ZOOM_ON_OBJECT | Zoom camera on cardboard (stub) |
| "person" | ZOOM_ON_OBJECT | Zoom camera on person (stub) |
| "bottle" | ZOOM_ON_OBJECT | Zoom camera on bottle (stub) |

*Add custom commands by editing the `_initialize_rules()` method in `orchestrator.py`*

## ğŸ”§ Configuration

### PDF Server (`pdf_server.py`)
- **Port**: 9002
- **PDF File**: `try.pdf` (place your PDF in project root)
- **Endpoints**:
  - `/viewer` - For web clients viewing slides
  - `/control` - For orchestrator to send commands
- **Render Quality**: 2x zoom for high-quality slides

### Audio STT Server (`main.py`)
- **Port**: 8765
- **Model**: Vosk STT (English/French)
- **Device**: Auto-detects MPS (Apple Silicon) or CPU
- **Sample Rate**: 24kHz
- **Chunk Duration**: ~80ms for low latency

### Orchestrator (`orchestrator.py`)
- **Port**: 9001
- **Rule Engine**: Keyword-based matching
- **Extensibility**: Add rules in `_initialize_rules()`
- **Logging**: Detailed command flow tracking

### VLM Server (Optional)
- **Port**: 8080
- **Model**: SmolVLM2-500M-Instruct
- **GPU Acceleration**: Enabled with `-ngl 99`

## ğŸ“ Project Structure

```
smolvlm+audio/
â”œâ”€â”€ main.py                    # Audio STT WebSocket server
â”œâ”€â”€ pdf_server.py              # PDF presentation server
â”œâ”€â”€ orchestrator.py            # Central orchestrator agent
â”œâ”€â”€ CameraController.py        # Camera control stub
â”œâ”€â”€ SlideController.py         # Slide control stub (alternative)
â”œâ”€â”€ unified_interface.html     # Main web interface
â”œâ”€â”€ pdf_viewer.html           # Standalone PDF viewer
â”œâ”€â”€ index.html                # Legacy VLM+Audio interface
â”œâ”€â”€ start_all.sh              # Automated startup script
â”œâ”€â”€ try.pdf                   # Your presentation PDF
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ STARTUP_GUIDE.md          # Detailed startup instructions
â”œâ”€â”€ ORCHESTRATOR_GUIDE.md     # Orchestrator documentation
â””â”€â”€ PDF_SYSTEM_README.md      # PDF system documentation
```

## ğŸ¨ Web Interfaces

### Unified Interface (`unified_interface.html`)
- **Split-screen layout**: PDF viewer on left, transcription on right
- **Real-time updates**: Slides change as you speak commands
- **Connection status**: Visual indicators for all services
- **Responsive design**: Works on various screen sizes

### PDF Viewer (`pdf_viewer.html`)
- **Standalone viewer**: View PDF without other features
- **Manual controls**: Button-based navigation
- **High-quality rendering**: Crisp, clear slides
- **Slide counter**: Shows current slide and total

## ğŸ§ª Testing the System

### Basic Test Flow

1. **Start all servers** (wait for "Ready" messages)
2. **Open unified interface** in browser
3. **Click "Start System"**
4. **Say "next slide"** - Should advance to slide 2
5. **Say "previous slide"** - Should return to slide 1
6. **Check terminal outputs** - See orchestrator logs

### Verifying Components

**Audio STT Working**:
- Speak into microphone
- See transcription appear in real-time
- Check terminal: "Listening for audio to transcribe..."

**Orchestrator Working**:
- Say "next slide"
- Terminal shows: "ORCHESTRATOR: Intent recognized from 'audio_stt'"
- Terminal shows: "Delegating command: NEXT_SLIDE"

**PDF Server Working**:
- Slide image updates in browser
- Terminal shows: "PDF Controller: Next slide -> X/Y"
- Multiple clients can view simultaneously

## ğŸ› ï¸ Troubleshooting

### Port Already in Use
```bash
# Kill processes on specific ports
lsof -ti:8765 | xargs kill -9  # Audio STT
lsof -ti:9001 | xargs kill -9  # Orchestrator
lsof -ti:9002 | xargs kill -9  # PDF Server
lsof -ti:8080 | xargs kill -9  # VLM Server
```

### PDF Not Loading
- Ensure `try.pdf` exists in project root
- Check PDF server terminal for errors
- Verify PyMuPDF installed: `pip install PyMuPDF`

### Voice Commands Not Working
- Verify audio server is connected to orchestrator
- Check orchestrator terminal for received messages
- Speak clearly and include exact trigger phrases
- Ensure microphone permissions granted

### Slides Not Updating
- Check PDF server connection in orchestrator terminal
- Verify browser WebSocket connection (unified_interface.html)
- Look for errors in browser console (F12)

### NumPy/PyTorch Errors
```bash
pip uninstall numpy
pip install "numpy<2.0"
pip install torch
```

## ğŸ”® Future Enhancements

### Planned Features
- [ ] **SmolVLM Integration**: Vision-based slide navigation
- [ ] **Real Camera Control**: PTZ camera integration
- [ ] **Natural Language Understanding**: More flexible command parsing
- [ ] **Slide Content Analysis**: VLM reads and answers questions about slides
- [ ] **Multi-presentation Support**: Switch between different PDFs
- [ ] **Presentation Notes**: Display speaker notes synchronized with slides
- [ ] **Recording**: Save presentation with voice and slide timing
- [ ] **Remote Control**: Mobile app interface

### Extending the System

**Add New Voice Commands**:
Edit `orchestrator.py`:
```python
def _initialize_rules(self):
    return {
        'audio_stt': [
            {
                'trigger': 'your custom phrase',
                'action': 'YOUR_ACTION',
                'params': {'key': 'value'}
            },
        ]
    }
```

**Implement Camera Control**:
Edit `CameraController.py` to integrate with actual camera hardware or software APIs.

**Change PDF File**:
Modify `pdf_server.py`:
```python
pdf_path = Path("your_presentation.pdf")
```

## ğŸ“ Use Cases

- ğŸ¤ **Voice-Controlled Presentations**: Hands-free slide navigation during talks
- â™¿ **Accessibility**: Assistive technology for users with mobility limitations
- ğŸ“¹ **Remote Presentations**: Control slides via voice in video conferences
- ğŸ¤– **AI Research**: Study multimodal agent architectures
- ğŸ“ **Education**: Interactive teaching with voice-controlled content
- ğŸ”¬ **Demo Systems**: Showcase AI capabilities to stakeholders
- ğŸ’¼ **Corporate Training**: Hands-free training presentations

## ğŸ“š Technical Details

### Models
- **Audio STT**: Vosk STT (~1-2GB download)
- **Vision VLM**: SmolVLM2-500M-Instruct GGUF (~500MB download)
- **PDF Rendering**: PyMuPDF (MuPDF engine)

### Frameworks & Libraries
- **Backend**: Python 3.12, asyncio, WebSockets
- **AI Models**: PyTorch, llama.cpp, Moshi
- **PDF Processing**: PyMuPDF (fitz), Pillow
- **Audio**: PyAudio, PortAudio
- **Frontend**: Vanilla JavaScript, WebSocket API

### Communication Protocol
- **Format**: JSON over WebSocket
- **Message Structure**:
  ```json
  {
    "source": "audio_stt",
    "content": "transcribed text"
  }
  ```
- **Command Structure**:
  ```json
  {
    "action": "NEXT_SLIDE",
    "params": {}
  }
  ```

### Performance
- **Audio Latency**: ~80-100ms (STT processing)
- **Command Recognition**: <50ms (Orchestrator)
- **Slide Update**: ~100-200ms (Render + Network)
- **End-to-End**: ~250-400ms (Speech â†’ Slide change)

- [SmolVLM](https://huggingface.co/HuggingFaceTB/SmolVLM2-500M-Instruct) by HuggingFace
- [Vosk](https://github.com/Jay113910/Speech-to-Text-Vosk) by Jay113910
- [llama.cpp](https://github.com/ggml-org/llama.cpp) by ggml.org

## License

See [LICENSE](LICENSE) file for details.
# smolvlm-audio-transcription
