# üé¨ AI Director - Multi-Stream Video Analysis System

Sistema di analisi video in tempo reale con supporto CUDA, progettato per Windows e integrazione con n8n.

## üéØ Caratteristiche Principali

- ‚úÖ **Analisi Video in Tempo Reale**: Processa video locali con SmolVLM
- ‚úÖ **Trascrizione Audio**: Estrae e trascrive l'audio dai video usando Moshi STT
- ‚úÖ **Supporto CUDA**: Accelerazione GPU per prestazioni ottimali
- ‚úÖ **Modelli Intercambiabili**: Cambia facilmente tra modelli di diverse dimensioni
- ‚úÖ **API REST**: Integrazione con n8n e altri orchestrator
- ‚úÖ **Multi-Stream**: Gestisci pi√π flussi video contemporaneamente
- ‚úÖ **WebSocket Real-Time**: Streaming dei risultati in tempo reale

## üìã Requisiti di Sistema

### Hardware
- **GPU**: NVIDIA con CUDA 11.x o 12.x (consigliato)
- **VRAM**: Minimo 4GB (8GB+ consigliato per modelli pi√π grandi)
- **RAM**: Minimo 8GB (16GB+ consigliato)
- **Storage**: 10GB+ per modelli e dipendenze

### Software
- **Windows 10/11**
- **Python 3.10+**
- **CUDA Toolkit** (se si usa GPU)
- **FFmpeg** (per elaborazione video/audio)

## üöÄ Installazione Rapida

### 1. Clona e Naviga nella Directory
```powershell
cd e:\dev\ai-director\smolvlm-audio-transcription
```

### 2. Esegui lo Script di Avvio
```powershell
.\start.ps1
```

Lo script automaticamente:
- Crea l'ambiente virtuale
- Installa le dipendenze
- Verifica la disponibilit√† CUDA
- Offre un menu interattivo

## üìñ Guida all'Uso

### Opzione 1: Server API (per n8n)

Avvia il server API per l'integrazione con n8n:

```powershell
.\start.ps1
# Seleziona opzione 1
```

Il server sar√† disponibile su:
- API: `http://localhost:8000`
- Documentazione: `http://localhost:8000/docs`
- WebSocket: `ws://localhost:8765`

### Opzione 2: Elaborazione Video Standalone

Elabora un singolo video:

```powershell
.\start.ps1
# Seleziona opzione 2
# Inserisci il percorso del video
```

Oppure direttamente:

```powershell
.\.venv\Scripts\Activate.ps1
python main_video.py "percorso\al\video.mp4"
```

Poi apri `index_video.html` nel browser.

### Opzione 3: Configurazione Modelli

Gestisci i modelli:

```powershell
# Visualizza modelli attivi
python config_manager.py active

# Lista modelli STT disponibili
python config_manager.py list stt

# Cambia modello STT
python config_manager.py set-stt medium

# Lista modelli VLM disponibili
python config_manager.py list vlm

# Cambia modello VLM
python config_manager.py set-vlm medium

# Verifica utilizzo VRAM
python config_manager.py vram

# Suggerisci modelli per VRAM disponibile
python config_manager.py suggest 6
```

## üîß Configurazione

### File `config.json`

Personalizza le impostazioni del sistema:

```json
{
    "models": {
        "stt": {
            "small": {
                "repo": "kyutai/stt-1b-en_fr",
                "vram_gb": 2
            }
        }
    },
    "server": {
        "host": "localhost",
        "websocket_port": 8765,
        "http_port": 8000,
        "max_concurrent_streams": 4
    },
    "video": {
        "default_fps": 30,
        "enable_audio": true,
        "loop_video": true
    }
}
```

## üåê API REST Endpoints

### Stream Management

#### Crea un nuovo stream
```bash
POST /streams/create
{
    "video_path": "video.mp4",
    "enable_audio": true,
    "stream_name": "Camera 1",
    "loop": true
}
```

#### Lista streams attivi
```bash
GET /streams
```

#### Controlla stream
```bash
POST /streams/{stream_id}/control
{
    "action": "start"  # start, stop, pause, resume
}
```

#### Elimina stream
```bash
DELETE /streams/{stream_id}
```

### Analysis

#### Ottieni risultati analisi
```bash
GET /analysis/{stream_id}?limit=100
```

#### Query analisi
```bash
POST /analysis/query
{
    "stream_id": "...",
    "query": "person detected",
    "max_results": 10
}
```

### Models

#### Lista modelli
```bash
GET /models
```

#### Cambia modello
```bash
POST /models/switch
{
    "model_type": "stt",
    "size": "medium"
}
```

### System

#### Health check
```bash
GET /health
```

#### Statistiche
```bash
GET /stats
```

## üîó Integrazione con n8n

### 1. Installa n8n
```powershell
npm install -g n8n
```

### 2. Avvia n8n
```powershell
n8n start
```

### 3. Importa Workflow
1. Apri n8n: `http://localhost:5678`
2. Importa `n8n-workflow-example.json`
3. Configura gli endpoint API

### 4. Esempio di Utilizzo

Il workflow di esempio:
1. Riceve un webhook con i dettagli del video
2. Crea uno stream video
3. Attende l'elaborazione
4. Recupera i risultati dell'analisi
5. Invia i risultati a un webhook

**Triggera il workflow:**
```bash
curl -X POST http://localhost:5678/webhook/ai-director-trigger \
  -H "Content-Type: application/json" \
  -d '{
    "video_path": "C:\\videos\\sample.mp4",
    "enable_audio": true,
    "stream_name": "Camera 1"
  }'
```

## üé¨ Architettura AI Director

### Concetto
Un sistema che:
1. Riceve multipli feed video
2. Analizza il contenuto in tempo reale
3. Decide quali feed mostrare in base al contenuto
4. Viene orchestrato da n8n

### Componenti

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      n8n                             ‚îÇ
‚îÇ                  (Orchestrator)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Video 1 ‚îÇ ‚îÇVid 2‚îÇ ‚îÇVid 3‚îÇ ‚îÇVid 4‚îÇ ‚îÇVid N‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
         ‚îÇ         ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ  AI Director   ‚îÇ
                   ‚îÇ  API Server    ‚îÇ
                   ‚îÇ   (FastAPI)    ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ   Analysis     ‚îÇ
                   ‚îÇ  VLM + STT     ‚îÇ
                   ‚îÇ   (CUDA)       ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Logica di Selezione Stream

Esempio di criteri per scegliere quale stream mostrare:
- **Priorit√† contenuto**: Persone > Movimento > Statico
- **Priorit√† audio**: Parlato > Rumore > Silenzio
- **Eventi**: Azioni > Oggetti interessanti
- **Custom**: Regole definite dall'utente

## üéØ Modelli Disponibili

### Speech-to-Text (STT)
| Dimensione | Modello | VRAM | Lingue | Note |
|-----------|---------|------|--------|------|
| Small | Moshi STT 1B | 2GB | EN, FR | Veloce, buona accuratezza |
| Medium | Moshi STT 2B | 4GB | EN, FR | Pi√π accurato, pi√π lento |

### Vision Language Model (VLM)
| Dimensione | Modello | VRAM | Note |
|-----------|---------|------|------|
| Small | SmolVLM 500M | 1GB | Veloce, real-time |
| Medium | SmolVLM 1.7B | 3GB | Pi√π dettagliato |

## üêõ Troubleshooting

### CUDA non disponibile
```powershell
# Verifica installazione CUDA
nvidia-smi

# Verifica PyTorch CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### Errore FFmpeg
```powershell
# Installa FFmpeg
choco install ffmpeg

# Verifica installazione
ffmpeg -version
```

### Porta occupata
```powershell
# Trova processo
netstat -ano | findstr :8000

# Termina processo
taskkill /PID <PID> /F
```

### Out of Memory (VRAM)
- Usa modelli "small"
- Riduci `max_concurrent_streams` in `config.json`
- Elabora video a risoluzione ridotta

## üìä Performance

### Benchmark Stimati (RTX 3060 12GB)

| Configurazione | FPS Video | Latenza STT | Streams Simultanei |
|----------------|-----------|-------------|-------------------|
| Small models | 30 | ~100ms | 4 |
| Medium models | 20 | ~150ms | 2 |
| Large models | 10 | ~250ms | 1 |

## üîÆ Roadmap

- [ ] Supporto per stream RTSP/HTTP in tempo reale
- [ ] Dashboard web per monitoraggio
- [ ] Rilevamento oggetti con YOLO
- [ ] Sistema di alerting basato su eventi
- [ ] Supporto per pi√π lingue STT
- [ ] Export timeline con annotazioni
- [ ] Integrazione con sistemi di videosorveglianza

## üìù License

Vedi file `LICENSE`

## ü§ù Contributi

Contributi benvenuti! Apri una issue o una pull request.

## üìß Supporto

Per problemi o domande, apri una issue su GitHub.

---

**Nota**: Questo progetto √® ottimizzato per uso locale su Windows con GPU CUDA. Per deployment su cloud o altri sistemi operativi, potrebbero essere necessarie modifiche.
